## CH01_04. 기계학습으로 문제를 해결하는 일반적인 순서

### 기계학습으로 문제를 해결하는 일반적인 순서
- 먼저 해결할 일(task)에 대해 input, output이 무엇인지 분석
- 관련된 데이터를 이해(Expolaratory data analysis; EDA)
- Train, Test 데이터를 대표성을 띄도록 임의로 나누고
  - 모델의 성능을 평가할 metric을 정의
- feature engineering과 modeling 진행
- 모델 최적화의 목표인 loss function을 정의
- 목적 함수(objective function)을 최소값으로 opimizationi할 기법 선택
- 모델 학습을 진행, 목표한대로 나왔는지 확인
- 위 과정 반복

### 먼저 해결할 일에 대해 input, output이 무엇인지 분석
- 분류 문제인가? 회귀분석 문제인가? 군집화 문제인가?
- 우리가 가지고 있는 데이터와 **상호 호환**이 되는가?

### 관련된 데이터를 이해
- EDA
- 데이터의 분포 및 값을 검토
- 데이터에 대한 잠재적인 문제 발견
  - 본격적인 분석에 들어가기 앞서 데이터의 수집
  - 모델링 시 주의할 점 파악
- 가설 수립(어떤 모델이 보다 좋을 것이다)

### Train, Test 데이터를 대표성을 띄도록 임의로 나누고, 모델의 성능을 평가할 metric을 정의
- 용어 정의
  - Train set: 머신 러닝 모델의 학습을 위해 사용
  - Validation set: 학습 중인 모델을 검증하기 위한 데이터
  - Test set: 학습과 검증이 완료된 모델의 최종적인 성능 평가
- 기계 학습 모델이 Train 데이터로 학습했을 때, 실제 서비스 환경에서는 Train 데이터로 들어올까?
  - No! 새로운 데이터가 들어옴
- 실제 기계 학습 필드에서는
  - 학습을 한 데이터가 아닌
  - **validation/test 데이터를 추가로 나누어**
  - Over fitting 등 **비정상 상태 여부**를 파악
- Validation, test가 따로 필요한 이유는 무엇일까?
  - Validation set은 학습 중 epoch 단위로 train 과정에서의 **중간 과정**에서 튜닝을 위해 존재
  - 즉, 이 과정에서 연구자에 의해 validation은 모니터링 되고,
    - 모델의 튜닝에 관여될 수 있음
  - 또한 validation set은 실험 환경에 따라 test set과 다를 수 있음
    - **test set**은 실제 **real-world** 환경이어야 함
  - 엄밀하게 구분하기 위해 **최종 평가는 Test set**을 통해 진행
- 모델을 평가할 성능 지표(metrics)을 정의
  - Classification(분류)
    - Accuracy, Recall, Precision, Sensivitiy, Specificity
    - AUC(Area Under the ROC Curve)
    - F1 Score, Fn Score
    - Cohen's Kappa Coefficient
  - Regression(회귀 분석)
    - Mean Absolute Error, Root Mean Square Error
    - R-squared(결정 계수; Coefficient of Determination)
  - Clustering(군집화)
    - Silhousette Score
    - Rand Index, Adjusted Rand Index
    - Mutual Information
    - Calinsk-Harabasz Index, Davies-Bouldin Index

### 피처엔지니어링과 모델링(학습 모델을 정의)
- featre engineering
  - 데이터의 **도메인 지식**을 이용하여 **머신러이 알고리즘**을 작동시키는 Feature를 만드는 과정
  - 일종의 전처리 과정
  - 고도화된 End-to-end 딥러닝 모델의 경우, 이 과정이 생략되는 경우도 있음
- 모델링
  - 머신러닝 모델을 정의하는 과정

### 모델 최적화의 목표인 손실 함수를 정의
- 손실 함수(loss function)
  - 이벤트로 생성된 값과 실제 값 사이의 cost, loss를 나타내는 함수
  - error function, cost function과 유사한 맥락
  - i.e. cross entropy loss, Bayesian expected loss, logisitc loss, L1, L2
- 최적화를 위한 목적 함수(objective function)
  - 최적화 알고리즘에 태워지는 궁극적인 함수
  - 보통, **손실 함수 자체**이거나 **손실 함수의 음수 값**

### 목표 함수를 최소값으로 optimization할 기법 선택
- optimization 문제
  - 최적화 변수 값을 값 탐색 범위 내에서 조절함으로써
  - 주어진 목적함수를 **최소화**혹은 **최대화**하는 해를 찾아내는 기법
- 방법
  - 경사 하강법(gradient descent)
  - 뉴턴법/뉴턴-랩슨법(Newton's step, Newton-Raphson)
- Optimizer
- **경사 하강법**이 일반적으로 많이 쓰이며, 여러 파생 연구가 많음
  - SGD, Adam, Momentum

### 모델 학습을 진행하고 목표한 대로 나왔는지 확인
- TensorBoard 등을 가지고 확인
  - Tensorflow에 PyTorch에서도 사용 가능
- wanddb.ai 등의 툴 활용
- traning error을 작게
- **test error와 training error의 차이를 작게**
- 부적합(underfit), 과적합(overfit)은 일어나지 않았는가?

#### Recap
- Underfit(부적합)
  - Train error를 줄이지 못한 경우
  - 모델의 용량(model capacity)를 키운다!
- Overfit(과적합)
  - Train error는 줄였으나, **Test Error**가 너무 큰 경우
  - 일반적으로는 **모델의 용량을 줄임**

#### 과적합을 방지하려면?
- Train data를 많이 모은다
  - 혹은 **데이터 증강 기법**(data augmentation) (TBD)를 사용
- feature의 개수를 줄인다
  - **정형화**가 쉽게 가능해짐
- Regularization(정형화)를 사용 (TBD)

#### Recent View
- **딥러닝**을 사용하고 **데이터**가 많으면서, 충분히 **모델이 깊다면**
  - 보다 더 **과적합**시켜도 됨
  - Deep Double Descent(2019) (TBD)
- 엄밀하게 증명되지는 않았으나, 최근 추세
