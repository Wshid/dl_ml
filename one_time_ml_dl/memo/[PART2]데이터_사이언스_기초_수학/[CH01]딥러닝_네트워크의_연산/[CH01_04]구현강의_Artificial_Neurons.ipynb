{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sWg9GHGpjPq"
      },
      "source": [
        "## 1-3: Activation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KJqyfSKplzF"
      },
      "source": [
        "## Code.1-3-1: Activation Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10Z0F7pPpoIO",
        "outputId": "9b9aa134-018c-4f94-ed9f-2a23bcdb021a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: (1, 5)\n",
            "[[ 0.8201937  -0.08602931 -0.23369314  0.00806955 -0.5787391 ]]\n",
            "Sigmoid(Tensorflow): (1, 5)\n",
            "[[0.69427747 0.47850594 0.44184116 0.5020174  0.3592228 ]]\n",
            "Sigmoid(manual): (1, 5)\n",
            "[[0.69427747 0.47850594 0.44184116 0.5020174  0.3592228 ]]\n",
            "\n",
            "Tanh(Tensorflow): (1, 5)\n",
            "[[ 0.67517537 -0.08581769 -0.22952987  0.00806937 -0.5217484 ]]\n",
            "Tanh(manual): (1, 5)\n",
            "[[ 0.67517525 -0.08581772 -0.22952986  0.00806937 -0.52174836]]\n",
            "\n",
            "Relu(Tensorflow): (1, 5)\n",
            "[[0.8201937  0.         0.         0.00806955 0.        ]]\n",
            "Relu(manual): (1, 5)\n",
            "[[0.8201937  0.         0.         0.00806955 0.        ]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.math import exp, maximum\n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "x = tf.random.normal(shape=(1, 5)) # input setting\n",
        "\n",
        "# imp. activation function\n",
        "sigmoid = Activation('sigmoid')\n",
        "tanh = Activation('tanh')\n",
        "relu = Activation('relu')\n",
        "\n",
        "# forward propagation(Tensorflow)\n",
        "y_sigmoid_tf = sigmoid(x)\n",
        "y_tanh_tf = tanh(x)\n",
        "y_relu_tf = relu(x)\n",
        "\n",
        "# forward propagation(manual)\n",
        "y_sigmod_man = 1 / (1 + exp(-x)) # exp(-x) -> e^-x\n",
        "y_tanh_man = (exp(x) - exp(-x))/(exp(x) + exp(-x))\n",
        "y_relu_man = maximum(x, 0)\n",
        "\n",
        "\n",
        "print(f'x: {x.shape}\\n{x.numpy()}')\n",
        "print(f'Sigmoid(Tensorflow): {y_sigmoid_tf.shape}\\n{y_sigmoid_tf.numpy()}')\n",
        "print(f'Sigmoid(manual): {y_sigmod_man.shape}\\n{y_sigmod_man.numpy()}\\n')\n",
        "\n",
        "print(f'Tanh(Tensorflow): {y_tanh_tf.shape}\\n{y_tanh_tf.numpy()}')\n",
        "print(f'Tanh(manual): {y_tanh_man.shape}\\n{y_tanh_man.numpy()}\\n')\n",
        "\n",
        "# relu의 경우 음수값은 모두 0. 처리\n",
        "print(f'Relu(Tensorflow): {y_relu_tf.shape}\\n{y_relu_tf.numpy()}')\n",
        "print(f'Relu(manual): {y_relu_man.shape}\\n{y_relu_man.numpy()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69baFYjzprBE"
      },
      "source": [
        "## Code.1-3-2. Activation in Dense Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L68Tn1NhpuBt",
        "outputId": "d83cf3a6-2c89-42c9-efd8-cd213fda69b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AN with Sigmoid: (1, 1),\n",
            "[[0.3426539]]\n",
            "AN with Tanh: (1, 1),\n",
            "[[0.13305978]]\n",
            "AN with ReLU : (1, 1),\n",
            "[[1.5421859]]\n",
            "Activation value(Tensorflow): (1, 1)\n",
            "[[0.3426539]]\n",
            "Avtivation value(manual): (1, 1)\n",
            "[[0.3426539]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x = tf.random.normal(shape=(1,5)) # input setting\n",
        "\n",
        "# imp. artifical neurons\n",
        "dense_sigmoid = Dense(units=1, activation='sigmoid') # 하나의 affine을 만들고 바로 activation(sigmoid 통과\n",
        "dense_tanh = Dense(units=1, activation='tanh')\n",
        "dense_relu = Dense(units=1, activation='relu')\n",
        "\n",
        "# forward propagation\n",
        "y_sigmoid = dense_sigmoid(x)\n",
        "y_tanh = dense_tanh(x)\n",
        "y_relu = dense_relu(x)\n",
        "\n",
        "print(f\"AN with Sigmoid: {y_sigmoid.shape},\\n{y_sigmoid.numpy()}\")\n",
        "print(f\"AN with Tanh: {y_tanh.shape},\\n{y_tanh.numpy()}\")\n",
        "print(f\"AN with ReLU : {y_relu.shape},\\n{y_relu.numpy()}\")\n",
        "\n",
        "\n",
        "# forward progation(manual)\n",
        "W, B = dense_sigmoid.get_weights()\n",
        "z = tf.linalg.matmul(x, W) + B\n",
        "a = 1 / (1 + exp(-z))\n",
        "# 공식 검증\n",
        "print(f'Activation value(Tensorflow): {y_sigmoid.shape}\\n{y_sigmoid.numpy()}')\n",
        "print(f'Avtivation value(manual): {a.shape}\\n{a.numpy()}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcyRJbMTpvaV"
      },
      "source": [
        "# 1-4: Artificial Neurons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_Aum3yep1e8"
      },
      "source": [
        "## Code.1-4-1: Artificial Neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSTprXVf3T27",
        "outputId": "40d1fb11-34dc-4ddb-b3ff-e00943454992"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Activation: relu\n",
            "y_tf: (1, 1)\n",
            "[[0.]]\n",
            "y_man: (1, 1)\n",
            "[[0.]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.math import exp, maximum\n",
        "\n",
        "# activation = 'sigmoid'\n",
        "# activation = 'tanh'\n",
        "activation = 'relu'\n",
        "\n",
        "x = tf.random.uniform(shape=(1, 10))\n",
        "dense = Dense(units=1, activation=activation) # imp. an affine + activation\n",
        "\n",
        "y_tf = dense(x)\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "# calculate activate value manually\n",
        "y_man = tf.linalg.matmul(x, W) + B\n",
        "if activation == 'sigmoid':\n",
        "  y_man = 1/(1 + exp(-y_man))\n",
        "elif activation == 'tanh':\n",
        "  y_man = (exp(y_man) - exp(-y_man))/(exp(y_man) + exp(-y_man))\n",
        "elif activation == 'relu':\n",
        "  y_man = maximum(y_man, 0)\n",
        "\n",
        "print(f\"Activation: {activation}\")\n",
        "print(f\"y_tf: {y_tf.shape}\\n{y_tf.numpy()}\")\n",
        "print(f\"y_man: {y_man.shape}\\n{y_man.numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCnLtcpJp8Sn"
      },
      "source": [
        "# 1-5: Minibatches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtS2m4YJ4rhA"
      },
      "source": [
        "## Code.1-5-1: Shapes of Dense Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abjBALXtpx0m",
        "outputId": "2982e1ba-8c98-4664-c2a5-31418d1c7ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of x: (8, 10)\n",
            "Shape of W: (10, 1)\n",
            "Shape of B: (1,)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# feature가 10개. N은 W, B에 영향을 미치지 X\n",
        "N, n_feature = 8, 10 # set input params\n",
        "x = tf.random.normal(shape=(N, n_feature)) # generate minibatch\n",
        "\n",
        "\n",
        "dense = Dense(units=1, activation='relu') # imp. an AN\n",
        "y = dense(x) # forward propagation\n",
        "\n",
        "W, B = dense.get_weights() # get weight/bias\n",
        "\n",
        "# print results\n",
        "print(f\"Shape of x: {x.shape}\")\n",
        "print(f\"Shape of W: {W.shape}\")\n",
        "print(f\"Shape of B: {B.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muIqF9Ii5qEF"
      },
      "source": [
        "## Code.1-5-2: Output Calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm2eF72T44Lr",
        "outputId": "f52cc57e-291d-4907-ac74-83b6309bc71c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output(Tensorflow): [[0.41156265]\n",
            " [0.9225304 ]\n",
            " [0.17103592]\n",
            " [0.7093222 ]\n",
            " [0.81265754]\n",
            " [0.9246201 ]\n",
            " [0.4728305 ]\n",
            " [0.38530356]]\n",
            "Output(Manual): [[0.41156265]\n",
            " [0.9225304 ]\n",
            " [0.17103592]\n",
            " [0.7093222 ]\n",
            " [0.8126575 ]\n",
            " [0.92462003]\n",
            " [0.47283044]\n",
            " [0.3853036 ]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 8, 10 # set input params\n",
        "x = tf.random.normal(shape=(N, n_feature)) # generate minibatch\n",
        "\n",
        "dense = Dense(units=1, activation='sigmoid') # imp. an AN\n",
        "y_tf = dense(x) # forward propagation\n",
        "\n",
        "W, B = dense.get_weights() # get weight/bias\n",
        "\n",
        "y_man = tf.linalg.matmul(x, W) + B # forward propagation(Manual)\n",
        "y_man = 1/(1 + tf.math.exp(-y_man))\n",
        "\n",
        "# print results\n",
        "print(f\"Output(Tensorflow): {y_tf.numpy()}\")\n",
        "print(f\"Output(Manual): {y_man.numpy()}\")\n",
        "\n",
        "# 아래 식은 동일 비교를 진행하나, floating point의 차이 발생으로 인해 오탐이 발생할 수 있음\n",
        "# print(tf.math.equal(y_tf, y_man))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKRE_z7T6Lt-"
      },
      "outputs": [],
      "source": [
        " "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
